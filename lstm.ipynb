{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ujson\n",
    "import gzip\n",
    "import string\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, islice\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import rnn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from headline_parser import parse_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_gz_lines(root):\n",
    "    \"\"\"Read JSON corpus.\n",
    "\n",
    "    Yields: dict\n",
    "    \"\"\"\n",
    "    for path in glob('%s/*.gz' % root):\n",
    "        with gzip.open(path) as fh:\n",
    "            for line in fh:\n",
    "                yield ujson.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_sizes(L, sizes):\n",
    "    \"\"\"Given a flat list and a list of sizes that sum to the length of the\n",
    "    list, group the list into sublists with corresponding sizes.\n",
    "\n",
    "    Args:\n",
    "        L (list)\n",
    "        sizes (list<int>)\n",
    "\n",
    "    Returns: list<list>\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    total = 0\n",
    "    for s in sizes:\n",
    "        parts.append(L[total:total+s])\n",
    "        total += s\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_replace(msg):\n",
    "    sys.stdout.write(f'\\r{msg}')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dump(cls, root, skim=None):\n",
    "        \n",
    "        rows_iter = islice(read_json_gz_lines(root), skim)\n",
    "        \n",
    "        # Label -> [line1, line2, ...]\n",
    "        # TODO: Parallelize.\n",
    "        groups = defaultdict(list)\n",
    "        for row in tqdm(rows_iter):\n",
    "            doc = parse_headline(row['title'])\n",
    "            spans = [s.text for s in doc._.spans]\n",
    "            for span in spans:\n",
    "                if span:\n",
    "                    groups[row['domain']].append(span)\n",
    "                \n",
    "        return cls(groups)\n",
    "    \n",
    "    def __init__(self, groups, test_frac=0.1):\n",
    "        self.groups = groups\n",
    "        self.test_frac = test_frac\n",
    "        self.set_splits()\n",
    "        \n",
    "    def labels(self):\n",
    "        return list(self.groups)\n",
    "        \n",
    "    def min_label_count(self):\n",
    "        return min([len(v) for v in self.groups.values()])\n",
    "    \n",
    "    def set_splits(self):\n",
    "        \n",
    "        min_count = self.min_label_count()\n",
    "        \n",
    "        pairs = list(chain(*[\n",
    "            [(line, label) for line in random.sample(lines, min_count)]\n",
    "            for label, lines in self.groups.items()\n",
    "        ]))\n",
    "        \n",
    "        test_size = round(len(pairs) * self.test_frac)\n",
    "        train_size = len(pairs) - (test_size * 2)\n",
    "        sizes = (train_size, test_size, test_size)\n",
    "        \n",
    "        self.train, self.val, self.test = random_split(pairs, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharEmbedding(nn.Embedding):\n",
    "\n",
    "    def __init__(self, embed_dim=15):\n",
    "        \"\"\"Set vocab, map s->i.\n",
    "        \"\"\"\n",
    "        self.vocab = (\n",
    "            string.ascii_letters +\n",
    "            string.digits +\n",
    "            string.punctuation\n",
    "        )\n",
    "\n",
    "        # <UNK> -> 1\n",
    "        self._ctoi = {s: i+1 for i, s in enumerate(self.vocab)}\n",
    "\n",
    "        super().__init__(len(self.vocab)+1, embed_dim)\n",
    "        \n",
    "    @property\n",
    "    def out_dim(self):\n",
    "        return self.weight.shape[1]\n",
    "\n",
    "    def ctoi(self, c):\n",
    "        return self._ctoi.get(c, 0)\n",
    "\n",
    "    def chars_to_idxs(self, chars):\n",
    "        \"\"\"Map characters to embedding indexes.\n",
    "        \"\"\"\n",
    "        idxs = [self.ctoi(c) for c in chars]\n",
    "\n",
    "        return torch.LongTensor(idxs).to(DEVICE)\n",
    "\n",
    "    def forward(self, chars):\n",
    "        \"\"\"Batch-embed chars.\n",
    "\n",
    "        Args:\n",
    "            tokens (list<str>)\n",
    "        \"\"\"\n",
    "        idxs = [self.ctoi(c) for c in chars]\n",
    "        x = torch.LongTensor(idxs).to(DEVICE)\n",
    "        \n",
    "        return super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=100, num_layers=1):\n",
    "        \"\"\"Initialize LSTM.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        self.out_dim = self.lstm.hidden_size * 2\n",
    "\n",
    "    def forward(self, xs):\n",
    "        \"\"\"Sort, pack, encode, reorder.\n",
    "\n",
    "        Args:\n",
    "            xs (list<Tensor>): Variable-length embedding tensors.\n",
    "\n",
    "        Returns:\n",
    "            x (Tensor): F/B hidden tops.\n",
    "        \"\"\"\n",
    "        sizes = [len(x) for x in xs]\n",
    "\n",
    "        # Indexes to sort descending.\n",
    "        sort_idxs = np.argsort(sizes)[::-1]\n",
    "\n",
    "        # Indexes to restore original order.\n",
    "        unsort_idxs = torch.from_numpy(np.argsort(sort_idxs)).to(DEVICE)\n",
    "\n",
    "        # Sort by size descending.\n",
    "        xs = [xs[i] for i in sort_idxs]\n",
    "\n",
    "        # Pad + pack, LSTM.\n",
    "        x = rnn.pack_sequence(xs)\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "\n",
    "        # Cat forward + backward hidden layers.\n",
    "        x = torch.cat([hn[0,:,:], hn[1,:,:]], dim=1)\n",
    "        x = x[unsort_idxs]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, labels, hidden_dim=100):\n",
    "        \"\"\"Initialize encoders + clf.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.labels = labels\n",
    "        self.ltoi = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "        self.embed_chars = CharEmbedding()\n",
    "        self.encode_spans = SpanEncoder(self.embed_chars.out_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(self.encode_spans.out_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, len(labels)),\n",
    "            nn.LogSoftmax(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, spans):\n",
    "        \"\"\"Predict outlet.\n",
    "        \"\"\"\n",
    "        sizes = [len(s) for s in spans]\n",
    "\n",
    "        # Embed chars, regroup by line.\n",
    "        x = self.embed_chars(list(chain(*spans)))\n",
    "        xs = group_by_sizes(x, sizes)\n",
    "\n",
    "        # Embed spans.\n",
    "        x = self.encode_spans(xs)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return self.predict(x)\n",
    "\n",
    "    def collate_batch(self, batch):\n",
    "        \"\"\"Labels -> indexes.\n",
    "        \"\"\"\n",
    "        lines, labels = list(zip(*batch))\n",
    "\n",
    "        yt_idx = [self.ltoi[label] for label in labels]\n",
    "        yt = torch.LongTensor(yt_idx).to(DEVICE)\n",
    "\n",
    "        return lines, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressDataLoader(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Track # generated pairs.\n",
    "        \"\"\"\n",
    "        self.n = 0\n",
    "\n",
    "        for x, y in super().__iter__():\n",
    "            self.n += len(x)\n",
    "            print_replace(f'{self.n}/{len(self.dataset)}\\r')\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:04, 2354.99it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus.from_dump('data/cleaning-titles.json/', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(c.labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(clf.parameters(), lr=1e-4)\n",
    "loss_func = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(split):\n",
    "\n",
    "    loader = DataLoader(\n",
    "        split,\n",
    "        collate_fn=clf.collate_batch,\n",
    "        batch_size=50,\n",
    "    )\n",
    "\n",
    "    losses = []\n",
    "    for spans, yt in tqdm(loader):\n",
    "\n",
    "        clf.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        yp = clf(spans)\n",
    "\n",
    "        loss = loss_func(yp, yt)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(split):\n",
    "    \n",
    "    clf.eval()\n",
    "\n",
    "    loader = DataLoader(\n",
    "        split,\n",
    "        collate_fn=clf.collate_batch,\n",
    "        batch_size=50,\n",
    "    )\n",
    "    \n",
    "    yt, yp = [], []\n",
    "    for lines, yti in loader:\n",
    "        yp += clf(lines).tolist()\n",
    "        yt += yti.tolist()\n",
    "        \n",
    "    yt = torch.LongTensor(yt)\n",
    "    yp = torch.FloatTensor(yp)\n",
    "        \n",
    "    return yt, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split):\n",
    "    yt, yp = predict(split)\n",
    "    return loss_func(yp, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.64it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:10,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3036)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.75it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:08,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.68it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:08,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.66it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:08,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.63it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:08,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2896)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.49it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:08,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2774)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.47it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:08,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2643)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.44it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:09,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.59it/s]\n",
      "  2%|▏         | 1/53 [00:00<00:09,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:08<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2402)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    train(corpus.train)\n",
    "    print(evaluate(corpus.val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2858)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(corpus.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(['opinion']).exp().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn.com'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.labels[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
